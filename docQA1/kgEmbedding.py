# ========================kgEmbedding.py===========================
"""
KG Database Retriever - ä½¿ç”¨ Embedding + Reranker æ£€ç´¢çŸ¥è¯†åº“

Embedding: /mnt/public/weights/bge-m3-finetune-v5
Reranker: /mnt/public/weights/bge-reranker-v2-gemma-v5
"""

import json
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
import torch
import os

os.environ['CUDA_VISIBLE_DEVICES'] = '6'

# ============ å…¨å±€é…ç½® ============
RETRIEVER_CONFIG = {
    # æ¨¡å‹è·¯å¾„
    "EMBED_MODEL_PATH": "/mnt/public/weights/bge-m3-finetune-v5",
    "RERANKER_MODEL_PATH": "/mnt/public/weights/bge-reranker-v2-gemma-v5",
    
    # æ£€ç´¢å‚æ•°
    "TOPK_RETRIEVE": 20,           # Embedding å¬å›æ•°é‡
    "TOPK_RERANK": 5,              # Reranker é‡æ’åä¿ç•™æ•°é‡
    "SCORE_THRESH": 0.3,           # é‡æ’åˆ†æ•°é˜ˆå€¼
    
    # è®¾å¤‡é…ç½®
    "DEVICE": "cuda" if torch.cuda.is_available() else "cpu",
    "BATCH_SIZE": 32,
}


@dataclass
class RetrievalResult:
    """æ£€ç´¢ç»“æœ"""
    id: str
    content: str
    score: float
    rank: int


class BGEEmbedding:
    """
    BGE-M3 Embedding æ¨¡å‹å°è£…
    """
    
    def __init__(
        self, 
        model_path: str = RETRIEVER_CONFIG["EMBED_MODEL_PATH"],
        device: str = RETRIEVER_CONFIG["DEVICE"],
    ):
        from transformers import AutoTokenizer, AutoModel
        
        print(f"ğŸ“¦ åŠ è½½ Embedding æ¨¡å‹: {model_path}")
        self.device = device
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModel.from_pretrained(model_path).to(device)
        self.model.eval()
        print(f"âœ… Embedding æ¨¡å‹åŠ è½½å®Œæˆ (device: {device})")
    
    def encode(
        self, 
        texts: List[str], 
        batch_size: int = RETRIEVER_CONFIG["BATCH_SIZE"],
        show_progress: bool = False,
    ) -> np.ndarray:
        """
        ç¼–ç æ–‡æœ¬ä¸ºå‘é‡
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            embeddings: shape (n_texts, embedding_dim)
        """
        all_embeddings = []
        
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]
            
            if show_progress:
                print(f"   Encoding batch {i // batch_size + 1}/{(len(texts) - 1) // batch_size + 1}")
            
            # Tokenize
            inputs = self.tokenizer(
                batch_texts,
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors="pt",
            ).to(self.device)
            
            # Encode
            with torch.no_grad():
                outputs = self.model(**inputs)
                # ä½¿ç”¨ [CLS] token çš„è¾“å‡ºä½œä¸ºå¥å­è¡¨ç¤º
                embeddings = outputs.last_hidden_state[:, 0, :]
                # L2 å½’ä¸€åŒ–
                embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)
                all_embeddings.append(embeddings.cpu().numpy())
        
        return np.vstack(all_embeddings)
    
    def encode_query(self, query: str) -> np.ndarray:
        """ç¼–ç å•ä¸ªæŸ¥è¯¢"""
        return self.encode([query])[0]


class BGEReranker:
    """
    BGE Reranker æ¨¡å‹å°è£…
    """
    
    def __init__(
        self,
        model_path: str = RETRIEVER_CONFIG["RERANKER_MODEL_PATH"],
        device: str = RETRIEVER_CONFIG["DEVICE"],
    ):
        from transformers import AutoTokenizer, AutoModelForSequenceClassification
        
        print(f"ğŸ“¦ åŠ è½½ Reranker æ¨¡å‹: {model_path}")
        self.device = device
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)
        self.model.eval()
        print(f"âœ… Reranker æ¨¡å‹åŠ è½½å®Œæˆ (device: {device})")
    
    def rerank(
        self,
        query: str,
        documents: List[Dict[str, str]],  # [{"id": ..., "content": ...}, ...]
        topk: int = RETRIEVER_CONFIG["TOPK_RERANK"],
        score_thresh: float = RETRIEVER_CONFIG["SCORE_THRESH"],
        batch_size: int = RETRIEVER_CONFIG["BATCH_SIZE"],
    ) -> List[Dict]:
        """
        å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’åº
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£åŒ…å« id å’Œ content
            topk: è¿”å›çš„æ–‡æ¡£æ•°é‡
            score_thresh: åˆ†æ•°é˜ˆå€¼
            
        Returns:
            é‡æ’åºåçš„æ–‡æ¡£åˆ—è¡¨ï¼ˆåŒ…å« rerank_scoreï¼‰
        """
        if not documents:
            return []
        
        # æ„å»º query-document pairs
        pairs = [[query, doc["content"]] for doc in documents]
        
        # æ‰¹é‡è®¡ç®—åˆ†æ•°
        all_scores = []
        for i in range(0, len(pairs), batch_size):
            batch_pairs = pairs[i:i + batch_size]
            
            inputs = self.tokenizer(
                batch_pairs,
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors="pt",
            ).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                # å¯¹äºäºŒåˆ†ç±»æ¨¡å‹ï¼Œå–æ­£ç±»çš„ logit æˆ–ä½¿ç”¨ sigmoid
                scores = torch.sigmoid(outputs.logits[:, 0]).cpu().numpy()
                all_scores.extend(scores.tolist())
        
        # æ·»åŠ åˆ†æ•°åˆ°æ–‡æ¡£
        scored_docs = []
        for doc, score in zip(documents, all_scores):
            doc_with_score = doc.copy()
            doc_with_score["rerank_score"] = score
            scored_docs.append(doc_with_score)
        
        # è¿‡æ»¤ä½åˆ†æ–‡æ¡£
        filtered_docs = [
            doc for doc in scored_docs 
            if doc["rerank_score"] >= score_thresh
        ]
        
        # æŒ‰åˆ†æ•°é™åºæ’åº
        filtered_docs.sort(key=lambda x: x["rerank_score"], reverse=True)
        
        return filtered_docs[:topk]


class KGDatabaseRetriever:
    """
    KG æ•°æ®åº“æ£€ç´¢å™¨
    
    ä¸¤é˜¶æ®µæ£€ç´¢ï¼šEmbedding å¬å› + Reranker ç²¾æ’
    """
    
    def __init__(
        self,
        database_path: str,
        embed_model_path: str = RETRIEVER_CONFIG["EMBED_MODEL_PATH"],
        reranker_model_path: str = RETRIEVER_CONFIG["RERANKER_MODEL_PATH"],
        device: str = RETRIEVER_CONFIG["DEVICE"],
        build_index: bool = True,
    ):
        self.database_path = database_path
        self.device = device
        
        # åŠ è½½æ•°æ®åº“
        self.database = self._load_database(database_path)
        self.id_list = list(self.database.keys())
        self.content_list = list(self.database.values())
        print(f"âœ… åŠ è½½æ•°æ®åº“: {len(self.database)} æ¡è®°å½•")
        
        # åˆå§‹åŒ– Embedding æ¨¡å‹
        self.embedder = BGEEmbedding(model_path=embed_model_path, device=device)
        
        # åˆå§‹åŒ– Reranker æ¨¡å‹
        self.reranker = BGEReranker(model_path=reranker_model_path, device=device)
        
        # æ„å»ºç´¢å¼•
        if build_index:
            self.index = self._build_index()
        else:
            self.index = None
    
    def _load_database(self, path: str) -> Dict[str, str]:
        """åŠ è½½ KG æ•°æ®åº“"""
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _build_index(self) -> np.ndarray:
        """
        æ„å»ºå‘é‡ç´¢å¼•
        
        Returns:
            embeddings: shape (n_docs, embedding_dim)
        """
        print("ğŸ”¨ æ„å»ºå‘é‡ç´¢å¼•...")
        
        # è¿‡æ»¤ç©ºå†…å®¹
        valid_contents = [c for c in self.content_list if c.strip()]
        
        # ç¼–ç æ‰€æœ‰æ–‡æ¡£
        embeddings = self.embedder.encode(valid_contents, show_progress=True)
        
        print(f"âœ… ç´¢å¼•æ„å»ºå®Œæˆ: {embeddings.shape}")
        return embeddings
    
    def save_index(self, save_path: str):
        """ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶"""
        np.save(save_path, self.index)
        print(f"âœ… ç´¢å¼•å·²ä¿å­˜: {save_path}")
    
    def load_index(self, load_path: str):
        """ä»æ–‡ä»¶åŠ è½½ç´¢å¼•"""
        self.index = np.load(load_path)
        print(f"âœ… ç´¢å¼•å·²åŠ è½½: {self.index.shape}")
    
    def retrieve(
        self,
        query: str,
        topk_retrieve: int = RETRIEVER_CONFIG["TOPK_RETRIEVE"],
        topk_rerank: int = RETRIEVER_CONFIG["TOPK_RERANK"],
        score_thresh: float = RETRIEVER_CONFIG["SCORE_THRESH"],
    ) -> List[RetrievalResult]:
        """
        ä¸¤é˜¶æ®µæ£€ç´¢
        
        1. Embedding å¬å› topk_retrieve æ¡
        2. Reranker ç²¾æ’ï¼Œè¿”å› topk_rerank æ¡
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            topk_retrieve: Embedding å¬å›æ•°é‡
            topk_rerank: Reranker è¿”å›æ•°é‡
            score_thresh: åˆ†æ•°é˜ˆå€¼
            
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“Œ Query: {query}")
        
        # ========== Stage 1: Embedding å¬å› ==========
        query_embedding = self.embedder.encode_query(query)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ (ç”±äºå·²å½’ä¸€åŒ–ï¼Œç›´æ¥ç‚¹ç§¯)
        similarities = np.dot(self.index, query_embedding)
        
        # è·å– topk ç´¢å¼•
        topk_indices = np.argsort(similarities)[::-1][:topk_retrieve]
        
        print(f"   Stage 1 - Embedding å¬å›: {len(topk_indices)} æ¡")
        
        # æ„å»ºå€™é€‰æ–‡æ¡£
        candidates = []
        for idx in topk_indices:
            if self.content_list[idx].strip():  # è·³è¿‡ç©ºå†…å®¹
                candidates.append({
                    "id": self.id_list[idx],
                    "content": self.content_list[idx],
                    "embed_score": float(similarities[idx]),
                })
        
        # ========== Stage 2: Reranker ç²¾æ’ ==========
        reranked_docs = self.reranker.rerank(
            query=query,
            documents=candidates,
            topk=topk_rerank,
            score_thresh=score_thresh,
        )
        
        print(f"   Stage 2 - Reranker ç²¾æ’: {len(reranked_docs)} æ¡")
        
        # æ„å»ºè¿”å›ç»“æœ
        results = []
        for rank, doc in enumerate(reranked_docs, 1):
            results.append(RetrievalResult(
                id=doc["id"],
                content=doc["content"],
                score=doc["rerank_score"],
                rank=rank,
            ))
        
        return results
    
    def batch_retrieve(
        self,
        queries: List[str],
        topk_retrieve: int = RETRIEVER_CONFIG["TOPK_RETRIEVE"],
        topk_rerank: int = RETRIEVER_CONFIG["TOPK_RERANK"],
    ) -> Dict[str, List[RetrievalResult]]:
        """æ‰¹é‡æ£€ç´¢"""
        results = {}
        for query in queries:
            results[query] = self.retrieve(query, topk_retrieve, topk_rerank)
        return results


def print_results(results: List[RetrievalResult]):
    """æ‰“å°æ£€ç´¢ç»“æœ"""
    if not results:
        print("   âŒ æ— æ£€ç´¢ç»“æœ")
        return
        
    for r in results:
        print(f"\n  [{r.rank}] {r.id}")
        print(f"      Score: {r.score:.4f}")
        content_preview = r.content[:150] + "..." if len(r.content) > 150 else r.content
        print(f"      Content: {content_preview}")


# ============ æµ‹è¯•ç”¨ä¾‹ ============

# ç¤ºä¾‹æŸ¥è¯¢ï¼ˆEDA/èŠ¯ç‰‡è®¾è®¡é¢†åŸŸï¼‰
SAMPLE_QUERIES = [
    "å¦‚ä½•è®¾ç½®æ—¶åºçº¦æŸçš„æœ€å¤§è½¬æ¢æ—¶é—´",
    "report_timing å‘½ä»¤æ€ä¹ˆç”¨",
    "ä»€ä¹ˆæ˜¯ setup slack",
    "å¦‚ä½•ä¼˜åŒ– hold time violation",
    "clock skew æ€ä¹ˆå¤„ç†",
    "set_max_fanout çš„ç”¨æ³•",
    "å¦‚ä½•æŸ¥çœ‹å…³é”®è·¯å¾„",
    "æ—¶é’Ÿæ ‘ç»¼åˆçš„åŸºæœ¬æµç¨‹",
]


def create_sample_database(output_path: str):
    """åˆ›å»ºç¤ºä¾‹æ•°æ®åº“ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    sample_db = {
        "kg_Command_0001": "set_max_transition value [-clock] [-data] | è®¾ç½®æœ€å¤§è½¬æ¢æ—¶é—´çº¦æŸï¼Œç”¨äºæ§åˆ¶ä¿¡å·ä¸Šå‡/ä¸‹é™æ—¶é—´ | åº”ç”¨åœºæ™¯: æ—¶åºçº¦æŸè®¾ç½®",
        "kg_Command_0002": "report_timing [-from] [-to] [-max_paths n] | æŠ¥å‘Šæ—¶åºè·¯å¾„ä¿¡æ¯ï¼Œæ˜¾ç¤ºå…³é”®è·¯å¾„çš„è¯¦ç»†æ—¶åºåˆ†æç»“æœ",
        "kg_Command_0003": "set_max_fanout value object_list | è®¾ç½®æœ€å¤§æ‰‡å‡ºçº¦æŸï¼Œé™åˆ¶å•ä¸ªé©±åŠ¨å™¨é©±åŠ¨çš„è´Ÿè½½æ•°é‡",
        "kg_Command_0004": "report_clock_timing | æŠ¥å‘Šæ—¶é’Ÿè·¯å¾„çš„æ—¶åºä¿¡æ¯ï¼ŒåŒ…æ‹¬æ—¶é’Ÿå»¶è¿Ÿå’Œåæ–œ",
        "kg_Command_0005": "set_clock_uncertainty value | è®¾ç½®æ—¶é’Ÿä¸ç¡®å®šæ€§ï¼ŒåŒ…æ‹¬æŠ–åŠ¨å’Œåæ–œçš„è£•é‡",
        "kg_Concept_0001": "setup slack è¡¨ç¤ºæ•°æ®ä¿¡å·åˆ°è¾¾æ—¶é—´ä¸æ—¶é’Ÿè¾¹æ²¿ä¹‹é—´çš„è£•é‡ï¼Œæ­£å€¼è¡¨ç¤ºæ»¡è¶³æ—¶åºè¦æ±‚ï¼Œè´Ÿå€¼è¡¨ç¤ºæ—¶åºè¿è§„",
        "kg_Concept_0002": "hold time violation è¡¨ç¤ºæ•°æ®ä¿æŒæ—¶é—´ä¸è¶³ï¼Œæ•°æ®åœ¨æ—¶é’Ÿè¾¹æ²¿åå˜åŒ–è¿‡å¿«ï¼Œéœ€è¦å¢åŠ å»¶è¿Ÿæ¥ä¿®å¤",
        "kg_Concept_0003": "clock skew æ˜¯æ—¶é’Ÿä¿¡å·åˆ°è¾¾ä¸åŒå¯„å­˜å™¨çš„æ—¶é—´å·®å¼‚ï¼Œè¿‡å¤§ä¼šå¯¼è‡´æ—¶åºé—®é¢˜ï¼Œéœ€è¦é€šè¿‡æ—¶é’Ÿæ ‘ç»¼åˆæ¥ä¼˜åŒ–",
        "kg_Concept_0004": "å…³é”®è·¯å¾„ (critical path) æ˜¯è®¾è®¡ä¸­æ—¶åºè£•é‡æœ€å°çš„è·¯å¾„ï¼Œå†³å®šäº†èŠ¯ç‰‡çš„æœ€é«˜å·¥ä½œé¢‘ç‡",
        "kg_Concept_0005": "æ—¶é’Ÿæ ‘ç»¼åˆ (CTS) æ˜¯å°†æ—¶é’Ÿä¿¡å·å‡åŒ€åˆ†å¸ƒåˆ°æ‰€æœ‰æ—¶åºå•å…ƒçš„è¿‡ç¨‹ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–æ—¶é’Ÿåæ–œ",
        "kg_Flow_0001": "æ—¶é’Ÿæ ‘ç»¼åˆåŸºæœ¬æµç¨‹ï¼š1. å®šä¹‰æ—¶é’Ÿæº 2. è®¾ç½®æ—¶é’Ÿçº¦æŸ 3. æ„å»ºæ—¶é’Ÿæ ‘ 4. å¹³è¡¡æ—¶é’Ÿå»¶è¿Ÿ 5. éªŒè¯æ—¶é’Ÿè´¨é‡",
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(sample_db, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å·²åˆ›å»ºç¤ºä¾‹æ•°æ®åº“: {output_path}")
    return output_path


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="KG Database Retriever")
    parser.add_argument("--database", type=str, default="kg_database.json", help="æ•°æ®åº“è·¯å¾„")
    parser.add_argument("--query", type=str, default=None, help="å•ä¸ªæŸ¥è¯¢")
    parser.add_argument("--topk_retrieve", type=int, default=RETRIEVER_CONFIG["TOPK_RETRIEVE"], help="Embedding å¬å›æ•°é‡")
    parser.add_argument("--topk_rerank", type=int, default=RETRIEVER_CONFIG["TOPK_RERANK"], help="Reranker è¿”å›æ•°é‡")
    parser.add_argument("--create_sample", action="store_true", help="åˆ›å»ºç¤ºä¾‹æ•°æ®åº“")
    
    args = parser.parse_args()
    
    # æ›´æ–°å…¨å±€é…ç½®
    RETRIEVER_CONFIG["TOPK_RETRIEVE"] = args.topk_retrieve
    RETRIEVER_CONFIG["TOPK_RERANK"] = args.topk_rerank
    
    database_path = args.database
    
    # æ£€æŸ¥/åˆ›å»ºæ•°æ®åº“
    if args.create_sample or not Path(database_path).exists():
        database_path = create_sample_database(database_path)
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    print("\n" + "=" * 60)
    print("ğŸš€ åˆå§‹åŒ– KG Database Retriever")
    print("=" * 60)
    
    retriever = KGDatabaseRetriever(
        database_path=database_path,
        embed_model_path=RETRIEVER_CONFIG["EMBED_MODEL_PATH"],
        reranker_model_path=RETRIEVER_CONFIG["RERANKER_MODEL_PATH"],
    )
    
    # æ‰§è¡Œæ£€ç´¢
    print("\n" + "=" * 60)
    print("ğŸ” å¼€å§‹æ£€ç´¢")
    print("=" * 60)
    
    if args.query:
        # å•ä¸ªæŸ¥è¯¢
        queries = [args.query]
    else:
        # ä½¿ç”¨ç¤ºä¾‹æŸ¥è¯¢
        queries = SAMPLE_QUERIES
    
    for query in queries:
        results = retriever.retrieve(
            query=query,
            topk_retrieve=args.topk_retrieve,
            topk_rerank=args.topk_rerank,
        )
        print_results(results)
        print()


if __name__ == "__main__":
    main()