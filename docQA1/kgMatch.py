# =========================kgMatch.py=============================
"""
KG å®ä¾‹ååŒ¹é…æ£€ç´¢å™¨ - åŸºäºæ­£åˆ™/å­—ç¬¦ä¸²åŒ¹é…

æ— éœ€å‘é‡æ•°æ®åº“ï¼Œç›´æ¥åŒ¹é… query ä¸­æ˜¯å¦åŒ…å« KG å®ä¾‹å
"""

import os
import re
import json
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Set
from dataclasses import dataclass, field
from collections import defaultdict

os.environ['CUDA_VISIBLE_DEVICES'] = '5'

# ============ è·¯å¾„é…ç½® ============
# æ•°æ®åº“è·¯å¾„
DATABASE_PATH = "/mnt/public/sichuan_a/hyh/queryTest1/qaSchema/xtopDoc/docQA1/dataBase/textContent.json"
# æµ‹è¯•é—®é¢˜è·¯å¾„
BENCHMARK_PATH = "/mnt/public/sichuan_a/hyh/queryTest1/qaSchema/xtopDoc/docQA1/testData/gt_benchmark.json"
# è¾“å‡ºç»“æœè·¯å¾„
OUTPUT_PATH = "/mnt/public/sichuan_a/hyh/queryTest1/qaSchema/xtopDoc/docQA1/results/kgMatch_results.txt"


# ============ åŒ¹é…å™¨é…ç½® ============
MATCHER_CONFIG = {
    # åŒ¹é…æ¨¡å¼: "regex" | "exact" | "fuzzy"
    "MATCH_MODE": "regex",
    
    # æ­£åˆ™åŒ¹é…é€‰é¡¹
    "CASE_SENSITIVE": False,      # æ˜¯å¦åŒºåˆ†å¤§å°å†™
    "WORD_BOUNDARY": False,       # æ˜¯å¦ä½¿ç”¨å•è¯è¾¹ç•Œ \bï¼ˆä¸­æ–‡åœºæ™¯å»ºè®® Falseï¼‰
    
    # æ¨¡ç³ŠåŒ¹é…é€‰é¡¹ï¼ˆfuzzy æ¨¡å¼ï¼‰
    "FUZZY_THRESHOLD": 0.8,       # æ¨¡ç³ŠåŒ¹é…é˜ˆå€¼
    
    # ç»“æœè¿‡æ»¤
    "MIN_NAME_LENGTH": 2,         # æœ€å°å®ä¾‹åé•¿åº¦ï¼ˆè¿‡æ»¤å¤ªçŸ­çš„åå­—ï¼‰
    "MAX_RESULTS": 50,            # æœ€å¤§è¿”å›ç»“æœæ•°
    
    # ä¼˜å…ˆçº§æƒé‡ï¼ˆç”¨äºæ’åºï¼‰
    "PRIORITY_WEIGHTS": {
        "exact": 1.0,             # å®Œå…¨åŒ¹é…
        "case_insensitive": 0.9,  # å¤§å°å†™ä¸æ•æ„ŸåŒ¹é…
        "partial": 0.7,           # éƒ¨åˆ†åŒ¹é…
        "fuzzy": 0.6,             # æ¨¡ç³ŠåŒ¹é…
    },
}


@dataclass
class MatchResult:
    """åŒ¹é…ç»“æœ"""
    id: str                       # å®ä¾‹ ID
    name: str                     # åŒ¹é…åˆ°çš„å®ä¾‹å
    content: str                  # å®ä¾‹å†…å®¹
    match_type: str               # åŒ¹é…ç±»å‹: exact | case_insensitive | partial | fuzzy
    match_position: Tuple[int, int]  # åŒ¹é…ä½ç½® (start, end)
    score: float                  # åŒ¹é…åˆ†æ•°
    
    def to_dict(self) -> Dict:
        return {
            "id": self.id,
            "name": self.name,
            "content": self.content,
            "match_type": self.match_type,
            "match_position": self.match_position,
            "score": self.score,
        }


@dataclass 
class KGInstance:
    """KG å®ä¾‹"""
    id: str
    content: str
    names: List[str] = field(default_factory=list)  # å¯èƒ½æœ‰å¤šä¸ªåå­—/åˆ«å


class KGNameExtractor:
    """
    ä» KG å†…å®¹ä¸­æå–å®ä¾‹åç§°
    """
    
    @classmethod
    def extract_names(cls, instance_id: str, content: str) -> List[str]:
        """
        ä»å®ä¾‹å†…å®¹ä¸­æå–åç§°
        
        Args:
            instance_id: å®ä¾‹ ID
            content: å®ä¾‹å†…å®¹
            
        Returns:
            names: æå–åˆ°çš„åç§°åˆ—è¡¨
        """
        names = set()
        content_stripped = content.strip()
        
        # 1. ä» ID ä¸­æå–ï¼ˆå¦‚æœ ID åŒ…å«æœ‰æ„ä¹‰çš„åå­—ï¼‰
        # ä¾‹å¦‚: kg_Command_set_max_transition -> set_max_transition
        id_parts = instance_id.split('_')
        if len(id_parts) > 2:
            potential_name = '_'.join(id_parts[2:])
            if len(potential_name) >= MATCHER_CONFIG["MIN_NAME_LENGTH"]:
                names.add(potential_name)
        
        # 2. æå–å‘½ä»¤åï¼ˆè‹±æ–‡ä¸‹åˆ’çº¿æ ¼å¼ï¼‰
        # ä¾‹å¦‚: "set_max_transition value" -> set_max_transition
        cmd_match = re.match(r'^([a-z_][a-z0-9_]*)', content_stripped, re.IGNORECASE)
        if cmd_match:
            name = cmd_match.group(1)
            if len(name) >= MATCHER_CONFIG["MIN_NAME_LENGTH"]:
                names.add(name)
        
        # 3. æå–ä¸­æ–‡æœ¯è¯­åï¼ˆå¼€å¤´çš„ä¸­æ–‡è¯ï¼‰
        chinese_match = re.match(r'^([\u4e00-\u9fa5]{2,15})', content_stripped)
        if chinese_match:
            names.add(chinese_match.group(1))
        
        # 4. æå–æ‹¬å·ä¸­çš„è‹±æ–‡æœ¯è¯­
        # ä¾‹å¦‚: "ä¿æŒæ—¶é—´è¿è§„ (hold time violation)" -> hold time violation
        paren_terms = re.findall(r'\(([a-zA-Z][a-zA-Z0-9_\s\-]{1,40})\)', content)
        for term in paren_terms:
            term = term.strip()
            if len(term) >= MATCHER_CONFIG["MIN_NAME_LENGTH"]:
                names.add(term)
        
        # 5. æå–ç¼©å†™ï¼ˆå…¨å¤§å†™ï¼‰
        # ä¾‹å¦‚: "WNS (Worst Negative Slack)" -> WNS
        abbr_terms = re.findall(r'\b([A-Z]{2,6})\b', content)
        for term in abbr_terms:
            names.add(term)
        
        # 6. æå– pipe åˆ†éš”ç¬¦å‰çš„å†…å®¹
        # ä¾‹å¦‚: "set_max_fanout value | æè¿°" -> set_max_fanout
        if '|' in content_stripped:
            before_pipe = content_stripped.split('|')[0].strip()
            first_word = before_pipe.split()[0] if before_pipe else None
            if first_word and len(first_word) >= MATCHER_CONFIG["MIN_NAME_LENGTH"]:
                names.add(first_word)
        
        return list(names)


class KGInstanceMatcher:
    """
    KG å®ä¾‹ååŒ¹é…å™¨
    
    é€šè¿‡æ­£åˆ™/å­—ç¬¦ä¸²åŒ¹é…æ£€æµ‹ query ä¸­æ˜¯å¦åŒ…å« KG å®ä¾‹å
    """
    
    def __init__(
        self,
        kg_data: Dict[str, str] = None,
        kg_file_path: str = None,
        config: Dict = None,
        verbose: bool = True,
    ):
        """
        åˆå§‹åŒ–åŒ¹é…å™¨
        
        Args:
            kg_data: KG æ•°æ®å­—å…¸ {content: id} æˆ– {id: content}
            kg_file_path: KG æ•°æ®æ–‡ä»¶è·¯å¾„
            config: é…ç½®è¦†ç›–
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        self.verbose = verbose
        
        # æ›´æ–°é…ç½®
        if config:
            MATCHER_CONFIG.update(config)
        
        # åŠ è½½æ•°æ®
        if kg_data:
            self.kg_data = kg_data
        elif kg_file_path:
            self.kg_data = self._load_kg_file(kg_file_path)
        else:
            raise ValueError("å¿…é¡»æä¾› kg_data æˆ– kg_file_path")
        
        # è½¬æ¢æ•°æ®æ ¼å¼ä¸º {id: content}
        self.kg_data = self._normalize_data(self.kg_data)
        
        # æ„å»ºå®ä¾‹ç´¢å¼•
        self.instances: List[KGInstance] = []
        self.name_to_instance: Dict[str, List[KGInstance]] = defaultdict(list)
        self._build_index()
        
        if self.verbose:
            print(f"KG å®ä¾‹åŒ¹é…å™¨åˆå§‹åŒ–å®Œæˆ")
            print(f"   - å®ä¾‹æ•°é‡: {len(self.instances)}")
            print(f"   - åç§°æ•°é‡: {len(self.name_to_instance)}")
    
    def _load_kg_file(self, path: str) -> Dict[str, str]:
        """åŠ è½½ KG æ–‡ä»¶"""
        if self.verbose:
            print(f"åŠ è½½ KG æ–‡ä»¶: {path}")
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _normalize_data(self, data: Dict[str, str]) -> Dict[str, str]:
        """
        æ ‡å‡†åŒ–æ•°æ®æ ¼å¼ä¸º {id: content}
        
        è¾“å…¥å¯èƒ½æ˜¯:
        - {content: id} æ ¼å¼ (buildDatabase.py è¾“å‡º)
        - {id: content} æ ¼å¼
        """
        if not data:
            return {}
        
        # æ£€æŸ¥ç¬¬ä¸€ä¸ª key æ˜¯å¦åƒ IDï¼ˆä»¥ kg_ æˆ–æ•°å­—å¼€å¤´ï¼‰
        first_key = next(iter(data.keys()))
        first_value = data[first_key]
        
        # å¦‚æœ key çœ‹èµ·æ¥åƒå†…å®¹ï¼ˆè¾ƒé•¿çš„æ–‡æœ¬ï¼‰ï¼Œvalue çœ‹èµ·æ¥åƒ ID
        # åˆ™éœ€è¦ç¿»è½¬
        if len(first_key) > 50 or (
            isinstance(first_value, str) and 
            (first_value.startswith("kg_") or first_value[0].isdigit())
        ):
            if self.verbose:
                print("   æ£€æµ‹åˆ° {content: id} æ ¼å¼ï¼Œæ­£åœ¨è½¬æ¢...")
            # ç¿»è½¬ï¼š{content: id} -> {id: content}
            normalized = {}
            for content, ids in data.items():
                # ids å¯èƒ½æ˜¯ "id1, id2, id3" æ ¼å¼
                for id_str in ids.split(", "):
                    id_str = id_str.strip()
                    if id_str:
                        normalized[id_str] = content
            return normalized
        
        return data
    
    def _build_index(self):
        """æ„å»ºåç§°ç´¢å¼•"""
        if self.verbose:
            print("ğŸ”¨ æ„å»ºåç§°ç´¢å¼•...")
        
        for instance_id, content in self.kg_data.items():
            # æå–åç§°
            names = KGNameExtractor.extract_names(instance_id, content)
            
            # åˆ›å»ºå®ä¾‹å¯¹è±¡
            instance = KGInstance(
                id=instance_id,
                content=content,
                names=names,
            )
            self.instances.append(instance)
            
            # å»ºç«‹åç§°åˆ°å®ä¾‹çš„æ˜ å°„
            for name in names:
                name_lower = name.lower()
                self.name_to_instance[name_lower].append(instance)
        
        # æŒ‰åç§°é•¿åº¦é™åºæ’åºï¼ˆä¼˜å…ˆåŒ¹é…é•¿åç§°ï¼Œé¿å…çŸ­åç§°è¯¯åŒ¹é…ï¼‰
        self.sorted_names = sorted(
            self.name_to_instance.keys(),
            key=len,
            reverse=True
        )
        
        if self.verbose:
            total_names = sum(len(inst.names) for inst in self.instances)
            print(f"   - æå–åˆ° {total_names} ä¸ªåç§°")
    
    def _compile_pattern(self, name: str) -> re.Pattern:
        """ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼"""
        escaped_name = re.escape(name)
        
        if MATCHER_CONFIG["WORD_BOUNDARY"]:
            pattern = rf'\b{escaped_name}\b'
        else:
            pattern = escaped_name
        
        flags = 0 if MATCHER_CONFIG["CASE_SENSITIVE"] else re.IGNORECASE
        return re.compile(pattern, flags)
    
    def match_regex(self, query: str) -> List[MatchResult]:
        """
        æ­£åˆ™åŒ¹é…æ¨¡å¼
        """
        results = []
        matched_positions = set()
        
        for name in self.sorted_names:
            if len(name) < MATCHER_CONFIG["MIN_NAME_LENGTH"]:
                continue
            
            pattern = self._compile_pattern(name)
            
            for match in pattern.finditer(query):
                start, end = match.span()
                
                # æ£€æŸ¥æ˜¯å¦ä¸å·²åŒ¹é…ä½ç½®é‡å 
                overlap = False
                for pos in matched_positions:
                    if not (end <= pos[0] or start >= pos[1]):
                        overlap = True
                        break
                
                if overlap:
                    continue
                
                matched_positions.add((start, end))
                
                # ç¡®å®šåŒ¹é…ç±»å‹
                matched_text = match.group()
                if matched_text == name:
                    match_type = "exact"
                elif matched_text.lower() == name.lower():
                    match_type = "case_insensitive"
                else:
                    match_type = "partial"
                
                score = MATCHER_CONFIG["PRIORITY_WEIGHTS"].get(match_type, 0.5)
                
                for instance in self.name_to_instance[name.lower()]:
                    results.append(MatchResult(
                        id=instance.id,
                        name=name,
                        content=instance.content,
                        match_type=match_type,
                        match_position=(start, end),
                        score=score,
                    ))
        
        return results
    
    def match_exact(self, query: str) -> List[MatchResult]:
        """
        ç²¾ç¡®åŒ¹é…æ¨¡å¼ï¼ˆç®€å•çš„ in æ“ä½œï¼‰
        """
        results = []
        query_lower = query.lower()
        
        for name in self.sorted_names:
            if len(name) < MATCHER_CONFIG["MIN_NAME_LENGTH"]:
                continue
            
            name_lower = name.lower()
            
            start = 0
            while True:
                pos = query_lower.find(name_lower, start)
                if pos == -1:
                    break
                
                matched_text = query[pos:pos + len(name)]
                if matched_text == name:
                    match_type = "exact"
                    score = 1.0
                else:
                    match_type = "case_insensitive"
                    score = 0.9
                
                for instance in self.name_to_instance[name_lower]:
                    results.append(MatchResult(
                        id=instance.id,
                        name=name,
                        content=instance.content,
                        match_type=match_type,
                        match_position=(pos, pos + len(name)),
                        score=score,
                    ))
                
                start = pos + 1
        
        return results
    
    def match_fuzzy(self, query: str) -> List[MatchResult]:
        """
        æ¨¡ç³ŠåŒ¹é…æ¨¡å¼ï¼ˆåŸºäºç¼–è¾‘è·ç¦»ï¼‰
        """
        from difflib import SequenceMatcher
        
        results = []
        query_words = query.lower().split()
        threshold = MATCHER_CONFIG["FUZZY_THRESHOLD"]
        
        for name in self.sorted_names:
            if len(name) < MATCHER_CONFIG["MIN_NAME_LENGTH"]:
                continue
            
            name_lower = name.lower()
            
            for word in query_words:
                ratio = SequenceMatcher(None, word, name_lower).ratio()
                
                if ratio >= threshold:
                    pos = query.lower().find(word)
                    
                    for instance in self.name_to_instance[name_lower]:
                        results.append(MatchResult(
                            id=instance.id,
                            name=name,
                            content=instance.content,
                            match_type="fuzzy",
                            match_position=(pos, pos + len(word)),
                            score=ratio,
                        ))
        
        return results
    
    def match(
        self, 
        query: str, 
        mode: str = None,
        deduplicate: bool = True,
    ) -> List[MatchResult]:
        """
        æ‰§è¡ŒåŒ¹é…
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            mode: åŒ¹é…æ¨¡å¼ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å¼
            deduplicate: æ˜¯å¦å»é‡
            
        Returns:
            åŒ¹é…ç»“æœåˆ—è¡¨ï¼ˆæŒ‰åˆ†æ•°é™åºï¼‰
        """
        mode = mode or MATCHER_CONFIG["MATCH_MODE"]
        
        if mode == "regex":
            results = self.match_regex(query)
        elif mode == "exact":
            results = self.match_exact(query)
        elif mode == "fuzzy":
            results = self.match_fuzzy(query)
        else:
            raise ValueError(f"æœªçŸ¥çš„åŒ¹é…æ¨¡å¼: {mode}")
        
        # å»é‡ï¼ˆåŒä¸€å®ä¾‹åªä¿ç•™æœ€é«˜åˆ†ï¼‰
        if deduplicate:
            seen = {}
            for r in results:
                if r.id not in seen or r.score > seen[r.id].score:
                    seen[r.id] = r
            results = list(seen.values())
        
        # æŒ‰åˆ†æ•°é™åºæ’åº
        results.sort(key=lambda x: x.score, reverse=True)
        
        return results[:MATCHER_CONFIG["MAX_RESULTS"]]
    
    def retrieve(
        self,
        query: str,
        topk: int = 5,
        mode: str = None,
    ) -> List[Dict]:
        """
        æ£€ç´¢æ¥å£ï¼ˆä¸ kgEmbedding ä¿æŒä¸€è‡´ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            topk: è¿”å›ç»“æœæ•°é‡
            mode: åŒ¹é…æ¨¡å¼
            
        Returns:
            ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« id, content, score
        """
        results = self.match(query, mode=mode)
        
        return [
            {
                "id": r.id,
                "content": r.content,
                "score": r.score,
                "match_type": r.match_type,
                "matched_name": r.name,
            }
            for r in results[:topk]
        ]
    
    def batch_match(
        self, 
        queries: List[str],
        mode: str = None,
    ) -> Dict[str, List[MatchResult]]:
        """æ‰¹é‡åŒ¹é…"""
        return {q: self.match(q, mode) for q in queries}
    
    def get_all_names(self) -> List[str]:
        """è·å–æ‰€æœ‰å®ä¾‹åç§°"""
        return list(self.name_to_instance.keys())
    
    def get_instance_by_name(self, name: str) -> List[KGInstance]:
        """æ ¹æ®åç§°è·å–å®ä¾‹"""
        return self.name_to_instance.get(name.lower(), [])
    
    def search_names(self, pattern: str) -> List[str]:
        """æœç´¢åŒ¹é…æ¨¡å¼çš„åç§°"""
        regex = re.compile(pattern, re.IGNORECASE)
        return [name for name in self.sorted_names if regex.search(name)]


def print_match_results(query: str, results: List[MatchResult], max_show: int = 10):
    """æ‰“å°åŒ¹é…ç»“æœ"""
    print(f"\n{'='*70}")
    print(f"Query: {query}")
    print(f"   åŒ¹é…æ•°é‡: {len(results)}")
    
    if not results:
        print("   æ— åŒ¹é…ç»“æœ")
        return
    
    for i, r in enumerate(results[:max_show], 1):
        print(f"\n  [{i}] {r.id}")
        print(f"      åç§°: {r.name}")
        print(f"      ç±»å‹: {r.match_type} | åˆ†æ•°: {r.score:.2f}")
        print(f"      ä½ç½®: {r.match_position}")
        content_preview = r.content[:80] + "..." if len(r.content) > 80 else r.content
        print(f"      å†…å®¹: {content_preview}")
    
    if len(results) > max_show:
        print(f"\n   ... è¿˜æœ‰ {len(results) - max_show} ä¸ªç»“æœ")


# ============ ä¸»å‡½æ•° ============
def main():
    """ä¸»å‡½æ•° - è¯»å–æµ‹è¯•æ•°æ®å¹¶è¾“å‡ºç»“æœ"""
    
    print("\n" + "=" * 60)
    print("KG å®ä¾‹ååŒ¹é…æ£€ç´¢å™¨")
    print("=" * 60)
    
    # ========== 1. åˆå§‹åŒ–åŒ¹é…å™¨ ==========
    print("\nã€1ã€‘åˆå§‹åŒ–åŒ¹é…å™¨")
    print(f"   æ•°æ®åº“è·¯å¾„: {DATABASE_PATH}")
    
    matcher = KGInstanceMatcher(
        kg_file_path=DATABASE_PATH,
        verbose=True
    )
    
    # ========== 2. åŠ è½½æµ‹è¯•é—®é¢˜ ==========
    print(f"\nã€2ã€‘åŠ è½½æµ‹è¯•é—®é¢˜: {BENCHMARK_PATH}")
    with open(BENCHMARK_PATH, 'r', encoding='utf-8') as f:
        benchmark_data = json.load(f)
    print(f"   åŠ è½½å®Œæˆ: {len(benchmark_data)} ä¸ªé—®é¢˜")
    
    # ========== 3. ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ ==========
    output_dir = Path(OUTPUT_PATH).parent
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ========== 4. æ‰§è¡Œæ£€ç´¢å¹¶ä¿å­˜ç»“æœ ==========
    print("\n" + "=" * 60)
    print("ã€3ã€‘å¼€å§‹æ£€ç´¢æµ‹è¯•")
    print("=" * 60)
    
    with open(OUTPUT_PATH, 'w', encoding='utf-8') as out_file:
        for item in benchmark_data:
            question_id = item.get("id", "N/A")
            query = item.get("question", "")
            
            if not query:
                continue
            
            # æ‰§è¡Œæ£€ç´¢
            results = matcher.retrieve(
                query=query,
                topk=5,
                mode="regex"
            )
            
            # å†™å…¥æ–‡ä»¶
            out_file.write("=" * 80 + "\n")
            out_file.write(f"ID: {question_id}\n")
            out_file.write(f"Question: {query}\n")
            out_file.write("-" * 80 + "\n")
            out_file.write(f"æ£€ç´¢ç»“æœæ•°é‡: {len(results)}\n")
            out_file.write(f"ç»“æœIDåˆ—è¡¨: {[r['id'] for r in results]}\n")
            out_file.write("-" * 80 + "\n")
            
            for i, r in enumerate(results, 1):
                out_file.write(f"[{i}] ID: {r['id']} | Score: {r['score']:.4f} | Match: {r['match_type']}\n")
                out_file.write(f"    Matched Name: {r['matched_name']}\n")
                out_file.write(f"    Content: {r['content']}\n")
                out_file.write("\n")
            
            out_file.write("\n")
        
    
    print("\n" + "=" * 60)
    print(f"ç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_PATH}")
    print("=" * 60)


if __name__ == "__main__":
    main()